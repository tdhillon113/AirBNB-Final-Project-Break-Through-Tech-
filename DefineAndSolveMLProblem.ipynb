{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 8: Define and Solve an ML Problem of Your Choosing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT\n",
    "# Emilia Szynwald and Trinity Dhillon worked together!\n",
    "\n",
    "# Emilia's work is shown by -E or E\n",
    "\n",
    "\n",
    "# Trinity's work is shown by -T or T \n",
    "\n",
    "# They collabed a lot for the ideas so most code and analysis was spoken and discussed but the main person who coded and chose those ideas wrote E or T.\n",
    "\n",
    "# We also worked together while screensharing so the copy on Trinitys side may miss something but Emilias side has the full code and markdown cells!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab assignment, you will follow the machine learning life cycle and implement a model to solve a machine learning problem of your choosing. You will select a data set and choose a predictive problem that the data set supports.  You will then inspect the data with your problem in mind and begin to formulate a  project plan. You will then implement the machine learning project plan. \n",
    "\n",
    "You will complete the following tasks:\n",
    "\n",
    "1. Build Your DataFrame\n",
    "2. Define Your ML Problem\n",
    "3. Perform exploratory data analysis to understand your data.\n",
    "4. Define Your Project Plan\n",
    "5. Implement Your Project Plan:\n",
    "    * Prepare your data for your model.\n",
    "    * Fit your model to the training data and evaluate your model.\n",
    "    * Improve your model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Build Your DataFrame\n",
    "\n",
    "You will have the option to choose one of four data sets that you have worked with in this program:\n",
    "\n",
    "* The \"census\" data set that contains Census information from 1994: `censusData.csv`\n",
    "* Airbnb NYC \"listings\" data set: `airbnbListingsData.csv`\n",
    "* World Happiness Report (WHR) data set: `WHR2018Chapter2OnlineData.csv`\n",
    "* Book Review data set: `bookReviewsData.csv`\n",
    "\n",
    "Note that these are variations of the data sets that you have worked with in this program. For example, some do not include some of the preprocessing necessary for specific models. \n",
    "\n",
    "#### Load a Data Set and Save it as a Pandas DataFrame\n",
    "\n",
    "The code cell below contains filenames (path + filename) for each of the four data sets available to you.\n",
    "\n",
    "<b>Task:</b> In the code cell below, use the same method you have been using to load the data using `pd.read_csv()` and save it to DataFrame `df`. \n",
    "\n",
    "You can load each file as a new DataFrame to inspect the data before choosing your data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "      <th>neighborhood_overview</th>\n",
       "      <th>host_name</th>\n",
       "      <th>host_location</th>\n",
       "      <th>host_about</th>\n",
       "      <th>host_response_rate</th>\n",
       "      <th>host_acceptance_rate</th>\n",
       "      <th>host_is_superhost</th>\n",
       "      <th>host_listings_count</th>\n",
       "      <th>...</th>\n",
       "      <th>review_scores_communication</th>\n",
       "      <th>review_scores_location</th>\n",
       "      <th>review_scores_value</th>\n",
       "      <th>instant_bookable</th>\n",
       "      <th>calculated_host_listings_count</th>\n",
       "      <th>calculated_host_listings_count_entire_homes</th>\n",
       "      <th>calculated_host_listings_count_private_rooms</th>\n",
       "      <th>calculated_host_listings_count_shared_rooms</th>\n",
       "      <th>reviews_per_month</th>\n",
       "      <th>n_host_verifications</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skylit Midtown Castle</td>\n",
       "      <td>Beautiful, spacious skylit studio in the heart...</td>\n",
       "      <td>Centrally located in the heart of Manhattan ju...</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>New York, New York, United States</td>\n",
       "      <td>A New Yorker since 2000! My passion is creatin...</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.17</td>\n",
       "      <td>True</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.79</td>\n",
       "      <td>4.86</td>\n",
       "      <td>4.41</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.33</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Whole flr w/private bdrm, bath &amp; kitchen(pls r...</td>\n",
       "      <td>Enjoy 500 s.f. top floor in 1899 brownstone, w...</td>\n",
       "      <td>Just the right mix of urban center and local n...</td>\n",
       "      <td>LisaRoxanne</td>\n",
       "      <td>New York, New York, United States</td>\n",
       "      <td>Laid-back Native New Yorker (formerly bi-coast...</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.69</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.80</td>\n",
       "      <td>4.71</td>\n",
       "      <td>4.64</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.86</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Spacious Brooklyn Duplex, Patio + Garden</td>\n",
       "      <td>We welcome you to stay in our lovely 2 br dupl...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rebecca</td>\n",
       "      <td>Brooklyn, New York, United States</td>\n",
       "      <td>Rebecca is an artist/designer, and Henoch is i...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.00</td>\n",
       "      <td>4.50</td>\n",
       "      <td>5.00</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Large Furnished Room Near B'way</td>\n",
       "      <td>Please don’t expect the luxury here just a bas...</td>\n",
       "      <td>Theater district, many restaurants around here.</td>\n",
       "      <td>Shunichi</td>\n",
       "      <td>New York, New York, United States</td>\n",
       "      <td>I used to work for a financial industry but no...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.42</td>\n",
       "      <td>4.87</td>\n",
       "      <td>4.36</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.68</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cozy Clean Guest Room - Family Apt</td>\n",
       "      <td>Our best guests are seeking a safe, clean, spa...</td>\n",
       "      <td>Our neighborhood is full of restaurants and ca...</td>\n",
       "      <td>MaryEllen</td>\n",
       "      <td>New York, New York, United States</td>\n",
       "      <td>Welcome to family life with my oldest two away...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.95</td>\n",
       "      <td>4.94</td>\n",
       "      <td>4.92</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.87</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  \\\n",
       "0                              Skylit Midtown Castle   \n",
       "1  Whole flr w/private bdrm, bath & kitchen(pls r...   \n",
       "2           Spacious Brooklyn Duplex, Patio + Garden   \n",
       "3                   Large Furnished Room Near B'way　   \n",
       "4                 Cozy Clean Guest Room - Family Apt   \n",
       "\n",
       "                                         description  \\\n",
       "0  Beautiful, spacious skylit studio in the heart...   \n",
       "1  Enjoy 500 s.f. top floor in 1899 brownstone, w...   \n",
       "2  We welcome you to stay in our lovely 2 br dupl...   \n",
       "3  Please don’t expect the luxury here just a bas...   \n",
       "4  Our best guests are seeking a safe, clean, spa...   \n",
       "\n",
       "                               neighborhood_overview    host_name  \\\n",
       "0  Centrally located in the heart of Manhattan ju...     Jennifer   \n",
       "1  Just the right mix of urban center and local n...  LisaRoxanne   \n",
       "2                                                NaN      Rebecca   \n",
       "3    Theater district, many restaurants around here.     Shunichi   \n",
       "4  Our neighborhood is full of restaurants and ca...    MaryEllen   \n",
       "\n",
       "                       host_location  \\\n",
       "0  New York, New York, United States   \n",
       "1  New York, New York, United States   \n",
       "2  Brooklyn, New York, United States   \n",
       "3  New York, New York, United States   \n",
       "4  New York, New York, United States   \n",
       "\n",
       "                                          host_about  host_response_rate  \\\n",
       "0  A New Yorker since 2000! My passion is creatin...                0.80   \n",
       "1  Laid-back Native New Yorker (formerly bi-coast...                0.09   \n",
       "2  Rebecca is an artist/designer, and Henoch is i...                1.00   \n",
       "3  I used to work for a financial industry but no...                1.00   \n",
       "4  Welcome to family life with my oldest two away...                 NaN   \n",
       "\n",
       "   host_acceptance_rate  host_is_superhost  host_listings_count  ...  \\\n",
       "0                  0.17               True                  8.0  ...   \n",
       "1                  0.69               True                  1.0  ...   \n",
       "2                  0.25               True                  1.0  ...   \n",
       "3                  1.00               True                  1.0  ...   \n",
       "4                   NaN               True                  1.0  ...   \n",
       "\n",
       "   review_scores_communication  review_scores_location  review_scores_value  \\\n",
       "0                         4.79                    4.86                 4.41   \n",
       "1                         4.80                    4.71                 4.64   \n",
       "2                         5.00                    4.50                 5.00   \n",
       "3                         4.42                    4.87                 4.36   \n",
       "4                         4.95                    4.94                 4.92   \n",
       "\n",
       "  instant_bookable calculated_host_listings_count  \\\n",
       "0            False                              3   \n",
       "1            False                              1   \n",
       "2            False                              1   \n",
       "3            False                              1   \n",
       "4            False                              1   \n",
       "\n",
       "   calculated_host_listings_count_entire_homes  \\\n",
       "0                                            3   \n",
       "1                                            1   \n",
       "2                                            1   \n",
       "3                                            0   \n",
       "4                                            0   \n",
       "\n",
       "   calculated_host_listings_count_private_rooms  \\\n",
       "0                                             0   \n",
       "1                                             0   \n",
       "2                                             0   \n",
       "3                                             1   \n",
       "4                                             1   \n",
       "\n",
       "   calculated_host_listings_count_shared_rooms  reviews_per_month  \\\n",
       "0                                            0               0.33   \n",
       "1                                            0               4.86   \n",
       "2                                            0               0.02   \n",
       "3                                            0               3.68   \n",
       "4                                            0               0.87   \n",
       "\n",
       "  n_host_verifications  \n",
       "0                    9  \n",
       "1                    6  \n",
       "2                    3  \n",
       "3                    4  \n",
       "4                    7  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File names of the four data sets\n",
    "adultDataSet_filename = os.path.join(os.getcwd(), \"data\", \"censusData.csv\")\n",
    "airbnbDataSet_filename = os.path.join(os.getcwd(), \"data\", \"airbnbListingsData.csv\")\n",
    "WHRDataSet_filename = os.path.join(os.getcwd(), \"data\", \"WHR2018Chapter2OnlineData.csv\")\n",
    "bookReviewDataSet_filename = os.path.join(os.getcwd(), \"data\", \"bookReviewsData.csv\")\n",
    "\n",
    "\n",
    "df = pd.read_csv(airbnbDataSet_filename) #E\n",
    "\n",
    "df.head() #E\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Define Your ML Problem\n",
    "\n",
    "Next you will formulate your ML Problem. In the markdown cell below, answer the following questions:\n",
    "\n",
    "1. List the data set you have chosen.\n",
    "2. What will you be predicting? What is the label?\n",
    "3. Is this a supervised or unsupervised learning problem? Is this a clustering, classification or regression problem? Is it a binary classificaiton or multi-class classifiction problem?\n",
    "4. What are your features? (note: this list may change after your explore your data)\n",
    "5. Explain why this is an important problem. In other words, how would a company create value with a model that predicts this label?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Airbnb NYC \"listings\" data set\n",
    "2. Predicting the price per night. The label is \"price\".\n",
    "3. This is a supervised learning problem and it is a regression problem. Therefore it isn't a binary or multi-class classification problem.\n",
    "4. Features: 'description', 'neighborhood_overview', 'host_location', 'host_about', 'host_response_rate', 'host_acceptance_rate', 'host_is_superhost', 'host_listings_count', 'host_total_listings_count', 'neighbourhood_group_cleansed', 'room_type','accommodates', 'bathrooms', 'bedrooms', 'beds', 'amenities', 'minimum_nights', 'maximum_nights', 'minimum_minimum_nights', 'maximum_minimum_nights', 'minimum_maximum_nights', 'maximum_maximum_nights', 'minimum_nights_avg_ntm','maximum_nights_avg_ntm', 'has_availability', 'availability_30','availability_60', 'availability_90', 'availability_365','number_of_reviews', 'number_of_reviews_ltm', 'number_of_reviews_l30d','review_scores_rating',  'review_scores_cleanliness','review_scores_checkin',  'review_scores_communication','review_scores_location', 'review_scores_value',  'instant_bookable','calculated_host_listings_count','calculated_host_listings_count_entire_homes', 'calculated_host_listings_count_private_rooms', 'calculated_host_listings_count_shared_rooms', 'reviews_per_month', 'n_host_verifications'\n",
    "5. Hosts can use it to properly price their listings to optimize revenue. The transparency with what price the listing could be based on others in its area helps customers choose an airbnb that isn't wildly priced. This helps the Airbnb website in customer trust.\n",
    "\n",
    "-E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Understand Your Data\n",
    "\n",
    "The next step is to perform exploratory data analysis. Inspect and analyze your data set with your machine learning problem in mind. Consider the following as you inspect your data:\n",
    "\n",
    "1. What data preparation techniques would you like to use? These data preparation techniques may include:\n",
    "\n",
    "    * addressing missingness, such as replacing missing values with means\n",
    "    * finding and replacing outliers\n",
    "    * renaming features and labels\n",
    "    * finding and replacing outliers\n",
    "    * performing feature engineering techniques such as one-hot encoding on categorical features\n",
    "    * selecting appropriate features and removing irrelevant features\n",
    "    * performing specific data cleaning and preprocessing techniques for an NLP problem\n",
    "    * addressing class imbalance in your data sample to promote fair AI\n",
    "    \n",
    "\n",
    "2. What machine learning model (or models) you would like to use that is suitable for your predictive problem and data?\n",
    "    * Are there other data preparation techniques that you will need to apply to build a balanced modeling data set for your problem and model? For example, will you need to scale your data?\n",
    " \n",
    " \n",
    "3. How will you evaluate and improve the model's performance?\n",
    "    * Are there specific evaluation metrics and methods that are appropriate for your model?\n",
    "    \n",
    "\n",
    "Think of the different techniques you have used to inspect and analyze your data in this course. These include using Pandas to apply data filters, using the Pandas `describe()` method to get insight into key statistics for each column, using the Pandas `dtypes` property to inspect the data type of each column, and using Matplotlib and Seaborn to detect outliers and visualize relationships between features and labels. If you are working on a classification problem, use techniques you have learned to determine if there is class imbalance.\n",
    "\n",
    "<b>Task</b>: Use the techniques you have learned in this course to inspect and analyze your data. You can import additional packages that you have used in this course that you will need to perform this task.\n",
    "\n",
    "<b>Note</b>: You can add code cells if needed by going to the <b>Insert</b> menu and clicking on <b>Insert Cell Below</b> in the drop-drown menu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "host_response_rate                              11843\n",
      "host_acceptance_rate                            11113\n",
      "host_about                                      10945\n",
      "neighborhood_overview                            9816\n",
      "bedrooms                                         2918\n",
      "beds                                             1354\n",
      "description                                       570\n",
      "host_location                                      60\n",
      "name                                                5\n",
      "availability_60                                     0\n",
      "availability_365                                    0\n",
      "number_of_reviews                                   0\n",
      "number_of_reviews_ltm                               0\n",
      "number_of_reviews_l30d                              0\n",
      "review_scores_rating                                0\n",
      "review_scores_cleanliness                           0\n",
      "availability_90                                     0\n",
      "review_scores_location                              0\n",
      "review_scores_checkin                               0\n",
      "review_scores_communication                         0\n",
      "has_availability                                    0\n",
      "review_scores_value                                 0\n",
      "instant_bookable                                    0\n",
      "calculated_host_listings_count                      0\n",
      "calculated_host_listings_count_entire_homes         0\n",
      "calculated_host_listings_count_private_rooms        0\n",
      "calculated_host_listings_count_shared_rooms         0\n",
      "reviews_per_month                                   0\n",
      "availability_30                                     0\n",
      "minimum_maximum_nights                              0\n",
      "maximum_nights_avg_ntm                              0\n",
      "minimum_nights_avg_ntm                              0\n",
      "host_name                                           0\n",
      "host_is_superhost                                   0\n",
      "host_listings_count                                 0\n",
      "host_total_listings_count                           0\n",
      "host_has_profile_pic                                0\n",
      "host_identity_verified                              0\n",
      "neighbourhood_group_cleansed                        0\n",
      "room_type                                           0\n",
      "accommodates                                        0\n",
      "bathrooms                                           0\n",
      "amenities                                           0\n",
      "price                                               0\n",
      "minimum_nights                                      0\n",
      "maximum_nights                                      0\n",
      "minimum_minimum_nights                              0\n",
      "maximum_minimum_nights                              0\n",
      "maximum_maximum_nights                              0\n",
      "n_host_verifications                                0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum().sort_values(ascending=False)) #E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Define Your Project Plan\n",
    "\n",
    "Now that you understand your data, in the markdown cell below, define your plan to implement the remaining phases of the machine learning life cycle (data preparation, modeling, evaluation) to solve your ML problem. Answer the following questions:\n",
    "\n",
    "* Do you have a new feature list? If so, what are the features that you chose to keep and remove after inspecting the data? \n",
    "* Explain different data preparation techniques that you will use to prepare your data for modeling.\n",
    "* What is your model (or models)?\n",
    "* Describe your plan to train your model, analyze its performance and then improve the model. That is, describe your model building, validation and selection plan to produce a model that generalizes well to new data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a new feature list: 'host_response_rate', 'host_acceptance_rate', 'host_listings_count', \n",
    "    'host_total_listings_count','neighbourhood_group_cleansed', 'room_type','accommodates', \n",
    "    'bathrooms','bedrooms', 'beds', 'minimum_nights', 'maximum_nights',\n",
    "    'minimum_minimum_nights', 'maximum_minimum_nights', 'minimum_maximum_nights', \n",
    "    'maximum_maximum_nights', 'minimum_nights_avg_ntm','maximum_nights_avg_ntm','number_of_reviews', 'number_of_reviews_ltm',\n",
    "    'number_of_reviews_l30d','review_scores_rating', 'review_scores_cleanliness',\n",
    "    'review_scores_checkin', 'review_scores_communication','review_scores_location',\n",
    "    'review_scores_value', 'calculated_host_listings_count',\n",
    "    'calculated_host_listings_count_entire_homes','calculated_host_listings_count_private_rooms',\n",
    "    'calculated_host_listings_count_shared_rooms', 'reviews_per_month'\n",
    "We will definitely use one hot encoding and fill in the blanks with mean values if numerical or null values if categorical. \n",
    "Our model will be a linear regression model, we will do a 80/20 train test split, and we will use the RSME and R^2 metrics to evaluate my model. We are also going to test out a NN and adjust the architecture in terms of neuron layers, and epoch sizes to get the best results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5: Implement Your Project Plan\n",
    "\n",
    "<b>Task:</b> In the code cell below, import additional packages that you have used in this course that you will need to implement your project plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import root_mean_squared_error, r2_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# -E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task:</b> Use the rest of this notebook to carry out your project plan. \n",
    "\n",
    "You will:\n",
    "\n",
    "1. Prepare your data for your model.\n",
    "2. Fit your model to the training data and evaluate your model.\n",
    "3. Improve your model's performance by performing model selection and/or feature selection techniques to find best model for your problem.\n",
    "\n",
    "Add code cells below and populate the notebook with commentary, code, analyses, results, and figures as you see fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Prepare data for model -E\n",
    "features = [\n",
    "    'host_response_rate', 'host_acceptance_rate', 'host_listings_count', \n",
    "    'host_total_listings_count','neighbourhood_group_cleansed', 'room_type','accommodates', \n",
    "    'bathrooms','bedrooms', 'beds', 'minimum_nights', 'maximum_nights',\n",
    "    'minimum_minimum_nights', 'maximum_minimum_nights', 'minimum_maximum_nights', \n",
    "    'maximum_maximum_nights', 'minimum_nights_avg_ntm','maximum_nights_avg_ntm','number_of_reviews', 'number_of_reviews_ltm',\n",
    "    'number_of_reviews_l30d','review_scores_rating', 'review_scores_cleanliness',\n",
    "    'review_scores_checkin', 'review_scores_communication','review_scores_location',\n",
    "    'review_scores_value', 'calculated_host_listings_count',\n",
    "    'calculated_host_listings_count_entire_homes','calculated_host_listings_count_private_rooms',\n",
    "    'calculated_host_listings_count_shared_rooms', 'reviews_per_month', 'price'\n",
    "] #E and T :)\n",
    "df = df[features]\n",
    "\n",
    "#filling in blanks\n",
    "ncols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "ccols = df.select_dtypes(include='object').columns\n",
    "df[ncols] = df[ncols].fillna(df[ncols].median())\n",
    "df[ccols] = df[ccols].fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encoding -E\n",
    "categorical_features = [\n",
    "    'neighbourhood_group_cleansed', 'room_type'\n",
    "]\n",
    "df = pd.get_dummies(df, columns=categorical_features, drop_first=True, sparse=True)\n",
    "df.head()\n",
    "\n",
    "df_LR = df.copy() #for Linear regression\n",
    "df_NN = df.copy() #for Neural Network\n",
    "\n",
    "#Split data -E\n",
    "y = df_LR['price']\n",
    "X = df_LR.drop(labels='price', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 106.16\n",
      "R^2: 0.42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/sklearn/utils/validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n",
      "/home/ubuntu/.pyenv/versions/3.9.19/lib/python3.9/site-packages/sklearn/utils/validation.py:869: UserWarning: pandas.DataFrame with sparse columns found.It will be converted to a dense numpy array.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_LR = LinearRegression()\n",
    "model_LR.fit(X_train, y_train)\n",
    "y_predictions = model_LR.predict(X_test)\n",
    "\n",
    "rmse = root_mean_squared_error(y_test, y_predictions)\n",
    "r2 = r2_score(y_test, y_predictions)\n",
    "print(f\"RMSE: {rmse:.2f}\")\n",
    "print(f\"R^2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "561/561 [==============================] - 1s 833us/step - loss: 43813317902336.0000 - mae: 233231.0156 - val_loss: 18344977629184.0000 - val_mae: 134520.2031\n",
      "Epoch 2/50\n",
      "561/561 [==============================] - 0s 700us/step - loss: 56246333865984.0000 - mae: 238916.9531 - val_loss: 204074254336.0000 - val_mae: 16831.1387\n",
      "Epoch 3/50\n",
      "561/561 [==============================] - 0s 689us/step - loss: 31485341990912.0000 - mae: 182467.5938 - val_loss: 1402478002176.0000 - val_mae: 49328.8164\n",
      "Epoch 4/50\n",
      "561/561 [==============================] - 0s 690us/step - loss: 2978827468800.0000 - mae: 60936.7734 - val_loss: 4061713399808.0000 - val_mae: 83252.5391\n",
      "Epoch 5/50\n",
      "561/561 [==============================] - 0s 691us/step - loss: 1599145377792.0000 - mae: 33436.1055 - val_loss: 162344517632.0000 - val_mae: 16340.1875\n",
      "Epoch 6/50\n",
      "561/561 [==============================] - 0s 709us/step - loss: 3293229875200.0000 - mae: 48504.7773 - val_loss: 5284793155584.0000 - val_mae: 97057.3516\n",
      "Epoch 7/50\n",
      "561/561 [==============================] - 0s 697us/step - loss: 17894586974208.0000 - mae: 117655.1016 - val_loss: 1455381151744.0000 - val_mae: 49034.8047\n",
      "Epoch 8/50\n",
      "561/561 [==============================] - 0s 692us/step - loss: 6912953810944.0000 - mae: 89016.6406 - val_loss: 7744966885376.0000 - val_mae: 109113.5469\n",
      "Epoch 9/50\n",
      "561/561 [==============================] - 0s 693us/step - loss: 1551755509760.0000 - mae: 25061.7656 - val_loss: 167945322496.0000 - val_mae: 15580.9902\n",
      "Epoch 10/50\n",
      "561/561 [==============================] - 0s 714us/step - loss: 2874531643392.0000 - mae: 46965.9453 - val_loss: 1366299508736.0000 - val_mae: 37490.9180\n",
      "Epoch 11/50\n",
      "561/561 [==============================] - 0s 698us/step - loss: 5050766721024.0000 - mae: 72248.0547 - val_loss: 2655203098624.0000 - val_mae: 62621.2539\n",
      "Epoch 12/50\n",
      "561/561 [==============================] - 0s 701us/step - loss: 14487014866944.0000 - mae: 106082.6875 - val_loss: 59945218048.0000 - val_mae: 10320.3457\n",
      "Epoch 13/50\n",
      "561/561 [==============================] - 0s 695us/step - loss: 50128461824.0000 - mae: 5181.5444 - val_loss: 499243616.0000 - val_mae: 842.5898\n",
      "Epoch 14/50\n",
      "561/561 [==============================] - 0s 692us/step - loss: 12108626944.0000 - mae: 3156.5571 - val_loss: 14194521088.0000 - val_mae: 3421.9072\n",
      "Epoch 15/50\n",
      "561/561 [==============================] - 0s 692us/step - loss: 13313208320.0000 - mae: 3116.2029 - val_loss: 1318368640.0000 - val_mae: 1260.1003\n",
      "Epoch 16/50\n",
      "561/561 [==============================] - 0s 693us/step - loss: 3857513216.0000 - mae: 1852.5530 - val_loss: 196500029440.0000 - val_mae: 12026.5303\n",
      "Epoch 17/50\n",
      "561/561 [==============================] - 0s 694us/step - loss: 1979600470016.0000 - mae: 43291.4727 - val_loss: 9996004352.0000 - val_mae: 4342.6274\n",
      "Epoch 18/50\n",
      "561/561 [==============================] - 0s 693us/step - loss: 34968543232.0000 - mae: 6250.8428 - val_loss: 11790934016.0000 - val_mae: 3796.9229\n",
      "Epoch 19/50\n",
      "561/561 [==============================] - 0s 698us/step - loss: 3700562591744.0000 - mae: 53060.5273 - val_loss: 584691023872.0000 - val_mae: 28111.2109\n",
      "Epoch 20/50\n",
      "561/561 [==============================] - 0s 694us/step - loss: 159976931328.0000 - mae: 9381.3408 - val_loss: 267004016.0000 - val_mae: 369.7582\n",
      "Epoch 21/50\n",
      "561/561 [==============================] - 0s 694us/step - loss: 137709040.0000 - mae: 341.8679 - val_loss: 99685408.0000 - val_mae: 298.6810\n",
      "Epoch 22/50\n",
      "561/561 [==============================] - 0s 694us/step - loss: 39807620.0000 - mae: 223.7413 - val_loss: 90201344.0000 - val_mae: 280.3959\n",
      "Epoch 23/50\n",
      "561/561 [==============================] - 0s 694us/step - loss: 29954740.0000 - mae: 192.1932 - val_loss: 139760256.0000 - val_mae: 467.6555\n",
      "Epoch 24/50\n",
      "561/561 [==============================] - 0s 694us/step - loss: 634471448576.0000 - mae: 15423.5361 - val_loss: 9820123955200.0000 - val_mae: 119913.4062\n",
      "Epoch 25/50\n",
      "561/561 [==============================] - 0s 701us/step - loss: 1807283519488.0000 - mae: 25996.0312 - val_loss: 26975784960.0000 - val_mae: 4858.3149\n",
      "Epoch 26/50\n",
      "561/561 [==============================] - 0s 691us/step - loss: 22898849792.0000 - mae: 4269.2861 - val_loss: 6693135872.0000 - val_mae: 3138.0637\n",
      "Epoch 27/50\n",
      "561/561 [==============================] - 0s 693us/step - loss: 4648136192.0000 - mae: 2036.1763 - val_loss: 5189095424.0000 - val_mae: 2893.1108\n",
      "Epoch 28/50\n",
      "561/561 [==============================] - 0s 692us/step - loss: 5399883776.0000 - mae: 1966.9813 - val_loss: 60013940736.0000 - val_mae: 8156.5015\n",
      "Epoch 29/50\n",
      "561/561 [==============================] - 0s 692us/step - loss: 257122844672.0000 - mae: 13637.5166 - val_loss: 435616608.0000 - val_mae: 950.7155\n",
      "Epoch 30/50\n",
      "561/561 [==============================] - 0s 696us/step - loss: 78149672960.0000 - mae: 8099.4165 - val_loss: 2673519104.0000 - val_mae: 1954.4362\n",
      "Epoch 31/50\n",
      "561/561 [==============================] - 0s 690us/step - loss: 2843347712.0000 - mae: 1608.3763 - val_loss: 840722496.0000 - val_mae: 1275.5656\n",
      "Epoch 32/50\n",
      "561/561 [==============================] - 0s 692us/step - loss: 10595394560.0000 - mae: 3595.9514 - val_loss: 612075392.0000 - val_mae: 1073.0909\n",
      "Epoch 33/50\n",
      "561/561 [==============================] - 0s 694us/step - loss: 196210982912.0000 - mae: 10379.8232 - val_loss: 538924224.0000 - val_mae: 998.5400\n",
      "Epoch 34/50\n",
      "561/561 [==============================] - 0s 695us/step - loss: 1674743296.0000 - mae: 1241.5298 - val_loss: 249183392.0000 - val_mae: 599.8369\n",
      "Epoch 35/50\n",
      "561/561 [==============================] - 0s 700us/step - loss: 286696160.0000 - mae: 586.7246 - val_loss: 227535968.0000 - val_mae: 619.9977\n",
      "Epoch 36/50\n",
      "561/561 [==============================] - 0s 698us/step - loss: 427973664.0000 - mae: 644.3275 - val_loss: 533588896.0000 - val_mae: 882.1111\n",
      "Epoch 37/50\n",
      "561/561 [==============================] - 0s 695us/step - loss: 13679960064.0000 - mae: 3986.4358 - val_loss: 16601652224.0000 - val_mae: 4426.8867\n",
      "Epoch 38/50\n",
      "561/561 [==============================] - 0s 694us/step - loss: 27929677824.0000 - mae: 5127.7695 - val_loss: 5851456512.0000 - val_mae: 2696.9263\n",
      "Epoch 39/50\n",
      "561/561 [==============================] - 0s 690us/step - loss: 1240479170560.0000 - mae: 25526.2168 - val_loss: 517947883520.0000 - val_mae: 27183.1016\n",
      "Epoch 40/50\n",
      "561/561 [==============================] - 0s 694us/step - loss: 261504155648.0000 - mae: 11100.2314 - val_loss: 50804498432.0000 - val_mae: 7317.9253\n",
      "Epoch 41/50\n",
      "561/561 [==============================] - 0s 691us/step - loss: 10268149760.0000 - mae: 2625.3083 - val_loss: 1260362240.0000 - val_mae: 1388.9777\n",
      "Epoch 42/50\n",
      "561/561 [==============================] - 0s 690us/step - loss: 3869931776.0000 - mae: 1692.8162 - val_loss: 905409216.0000 - val_mae: 1155.0557\n",
      "Epoch 43/50\n",
      "561/561 [==============================] - 0s 696us/step - loss: 1253858560.0000 - mae: 1240.7727 - val_loss: 157927488.0000 - val_mae: 517.9721\n",
      "Epoch 44/50\n",
      "561/561 [==============================] - 0s 690us/step - loss: 462651097088.0000 - mae: 15740.6201 - val_loss: 6584331776.0000 - val_mae: 3382.0212\n",
      "Epoch 45/50\n",
      "561/561 [==============================] - 0s 697us/step - loss: 5290065408.0000 - mae: 2245.4395 - val_loss: 2317853952.0000 - val_mae: 2079.9412\n",
      "Epoch 46/50\n",
      "561/561 [==============================] - 0s 688us/step - loss: 4916940288.0000 - mae: 2337.4243 - val_loss: 6619343872.0000 - val_mae: 3486.8887\n",
      "Epoch 47/50\n",
      "561/561 [==============================] - 0s 691us/step - loss: 40857489408.0000 - mae: 5638.2803 - val_loss: 3589241344.0000 - val_mae: 2393.4563\n",
      "Epoch 48/50\n",
      "561/561 [==============================] - 0s 692us/step - loss: 7098809856.0000 - mae: 2592.6313 - val_loss: 62783036.0000 - val_mae: 314.7680\n",
      "Epoch 49/50\n",
      "561/561 [==============================] - 0s 692us/step - loss: 354902912.0000 - mae: 674.0066 - val_loss: 81002432.0000 - val_mae: 372.7429\n",
      "Epoch 50/50\n",
      "561/561 [==============================] - 0s 693us/step - loss: 16566376448.0000 - mae: 3957.5459 - val_loss: 85500297216.0000 - val_mae: 12230.3945\n",
      "Test RMSE: 419215.06\n",
      "Test R^2: -8508812.56\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Split data -E\n",
    "y = df_NN['price']\n",
    "X = df_NN.drop(labels='price', axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "#BASE NN\n",
    "# Define model architecture -T\n",
    "model_NN = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1)  # Output layer for regression\n",
    "])\n",
    "\n",
    "# Compile the model -T\n",
    "model_NN.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the model -T\n",
    "history = model_NN.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,           \n",
    "    batch_size=32,\n",
    "    validation_split=0.2,   \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate Model -T\n",
    "y_pred = model_NN.predict(X_test).flatten()\n",
    "\n",
    "# Computing RMSE and R^2 -T\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Test RMSE: {rmse:.2f}\")\n",
    "print(f\"Test R^2: {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Analysis:\n",
    "# LR was much better than base NN. \n",
    "# Linear Regression Model:\n",
    "# RMSE: 110.73\n",
    "# R^2: 0.39\n",
    "\n",
    "# Neural Network Model:\n",
    "# Test RMSE: 74,375.01\n",
    "# Test R^2: -287,996.45\n",
    "\n",
    "#LR is doing decent and there's something \n",
    "# obviously wrong with the NN as R^2 should be close to 1 \n",
    "# for perfect and a RMSE as low as possible is best.\n",
    "# We will adjust the NN to see how close to the LR we can get.\n",
    "\n",
    "\n",
    "# -T and E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "561/561 [==============================] - 1s 854us/step - loss: 30678001385472.0000 - mae: 178333.6719 - val_loss: 2021966479360.0000 - val_mae: 55758.6484\n",
      "Epoch 2/50\n",
      "561/561 [==============================] - 0s 714us/step - loss: 8692310736896.0000 - mae: 93556.8438 - val_loss: 478223466496.0000 - val_mae: 23073.4883\n",
      "Epoch 3/50\n",
      "561/561 [==============================] - 0s 714us/step - loss: 602263126016.0000 - mae: 17846.1504 - val_loss: 200315977728.0000 - val_mae: 12603.8711\n",
      "Epoch 4/50\n",
      "561/561 [==============================] - 0s 715us/step - loss: 425877504000.0000 - mae: 17211.3848 - val_loss: 859386216448.0000 - val_mae: 35481.3320\n",
      "Epoch 5/50\n",
      "561/561 [==============================] - 0s 715us/step - loss: 2486587097088.0000 - mae: 44445.1367 - val_loss: 1668476960768.0000 - val_mae: 48343.4102\n",
      "Epoch 6/50\n",
      "561/561 [==============================] - 0s 718us/step - loss: 219369390080.0000 - mae: 12865.0742 - val_loss: 142872674304.0000 - val_mae: 11873.2061\n",
      "Epoch 7/50\n",
      "561/561 [==============================] - 0s 719us/step - loss: 965217419264.0000 - mae: 24780.7793 - val_loss: 597575467008.0000 - val_mae: 21540.5664\n",
      "Epoch 8/50\n",
      "561/561 [==============================] - 0s 712us/step - loss: 134577455104.0000 - mae: 5978.9312 - val_loss: 1208050688.0000 - val_mae: 1160.6434\n",
      "Epoch 9/50\n",
      "561/561 [==============================] - 0s 712us/step - loss: 617812096.0000 - mae: 808.7650 - val_loss: 2435884544.0000 - val_mae: 2012.2494\n",
      "Epoch 10/50\n",
      "561/561 [==============================] - 0s 718us/step - loss: 114798501888.0000 - mae: 7753.8296 - val_loss: 4554416128.0000 - val_mae: 2716.0259\n",
      "Epoch 11/50\n",
      "561/561 [==============================] - 0s 715us/step - loss: 124942770176.0000 - mae: 6953.2568 - val_loss: 114579685376.0000 - val_mae: 12851.5127\n",
      "Epoch 12/50\n",
      "561/561 [==============================] - 0s 717us/step - loss: 1026782527488.0000 - mae: 24975.5527 - val_loss: 149214880.0000 - val_mae: 517.8406\n",
      "Epoch 13/50\n",
      "561/561 [==============================] - 0s 714us/step - loss: 33383563264.0000 - mae: 4174.8013 - val_loss: 17664354304.0000 - val_mae: 4359.5195\n",
      "Epoch 14/50\n",
      "561/561 [==============================] - 0s 715us/step - loss: 6167894528.0000 - mae: 1990.8481 - val_loss: 1426378496.0000 - val_mae: 1183.5511\n",
      "Epoch 15/50\n",
      "561/561 [==============================] - 0s 720us/step - loss: 8390498816.0000 - mae: 2527.3833 - val_loss: 44888068096.0000 - val_mae: 7846.3979\n",
      "Epoch 16/50\n",
      "561/561 [==============================] - 0s 718us/step - loss: 123380154368.0000 - mae: 8518.0830 - val_loss: 51092791296.0000 - val_mae: 6142.0850\n",
      "Epoch 17/50\n",
      "561/561 [==============================] - 0s 713us/step - loss: 10086129664.0000 - mae: 2570.5464 - val_loss: 35775496192.0000 - val_mae: 6705.9595\n",
      "Epoch 18/50\n",
      "561/561 [==============================] - 0s 713us/step - loss: 9803795456.0000 - mae: 2580.2786 - val_loss: 694179520.0000 - val_mae: 1018.7029\n",
      "Epoch 19/50\n",
      "561/561 [==============================] - 0s 717us/step - loss: 51883257856.0000 - mae: 5488.3433 - val_loss: 32098885632.0000 - val_mae: 6650.7705\n",
      "Epoch 20/50\n",
      "561/561 [==============================] - 0s 719us/step - loss: 5986966016.0000 - mae: 1819.9683 - val_loss: 4897079808.0000 - val_mae: 2570.5911\n",
      "Epoch 21/50\n",
      "561/561 [==============================] - 0s 718us/step - loss: 16644857856.0000 - mae: 3218.4866 - val_loss: 3922615040.0000 - val_mae: 1854.4642\n",
      "Epoch 22/50\n",
      "561/561 [==============================] - 0s 718us/step - loss: 9940345856.0000 - mae: 2718.1741 - val_loss: 5447434240.0000 - val_mae: 2362.6072\n",
      "Epoch 23/50\n",
      "561/561 [==============================] - 0s 717us/step - loss: 13152313344.0000 - mae: 1378.6299 - val_loss: 28552478.0000 - val_mae: 285.3355\n",
      "Epoch 24/50\n",
      "561/561 [==============================] - 0s 716us/step - loss: 9792573.0000 - mae: 174.1557 - val_loss: 6749202.5000 - val_mae: 183.9591\n",
      "Epoch 25/50\n",
      "561/561 [==============================] - 0s 718us/step - loss: 2165513.0000 - mae: 128.3977 - val_loss: 1317122.2500 - val_mae: 128.7676\n",
      "Epoch 26/50\n",
      "561/561 [==============================] - 0s 717us/step - loss: 351372.5000 - mae: 102.3468 - val_loss: 165528.9219 - val_mae: 100.2804\n",
      "Epoch 27/50\n",
      "561/561 [==============================] - 0s 713us/step - loss: 55341.9023 - mae: 88.0130 - val_loss: 24881.6172 - val_mae: 84.5514\n",
      "Epoch 28/50\n",
      "561/561 [==============================] - 0s 714us/step - loss: 19009.3652 - mae: 80.7476 - val_loss: 17584.5645 - val_mae: 76.5172\n",
      "Epoch 29/50\n",
      "561/561 [==============================] - 0s 710us/step - loss: 16619.1309 - mae: 76.0018 - val_loss: 16584.8613 - val_mae: 73.6412\n",
      "Epoch 30/50\n",
      "561/561 [==============================] - 0s 714us/step - loss: 15664.9912 - mae: 73.2880 - val_loss: 15962.4492 - val_mae: 70.9854\n",
      "Epoch 31/50\n",
      "561/561 [==============================] - 0s 713us/step - loss: 15038.4922 - mae: 71.3844 - val_loss: 15058.4531 - val_mae: 68.4284\n",
      "Epoch 32/50\n",
      "561/561 [==============================] - 0s 715us/step - loss: 14333.3164 - mae: 69.2912 - val_loss: 14829.3174 - val_mae: 66.7108\n",
      "Epoch 33/50\n",
      "561/561 [==============================] - 0s 717us/step - loss: 13991.4082 - mae: 68.5748 - val_loss: 14197.4795 - val_mae: 66.2824\n",
      "Epoch 34/50\n",
      "561/561 [==============================] - 0s 716us/step - loss: 13607.8965 - mae: 67.5396 - val_loss: 14402.9229 - val_mae: 67.5078\n",
      "Epoch 35/50\n",
      "561/561 [==============================] - 0s 715us/step - loss: 13341.3564 - mae: 66.5487 - val_loss: 19752.7031 - val_mae: 65.4214\n",
      "Epoch 36/50\n",
      "561/561 [==============================] - 0s 717us/step - loss: 14638.9600 - mae: 66.2134 - val_loss: 233550.5000 - val_mae: 71.2495\n",
      "Epoch 37/50\n",
      "561/561 [==============================] - 0s 715us/step - loss: 959660752896.0000 - mae: 16239.4727 - val_loss: 5322738176.0000 - val_mae: 2890.5720\n",
      "Epoch 38/50\n",
      "561/561 [==============================] - 0s 714us/step - loss: 3896856576.0000 - mae: 2383.9238 - val_loss: 1201459968.0000 - val_mae: 1288.9634\n",
      "Epoch 39/50\n",
      "561/561 [==============================] - 0s 717us/step - loss: 1097109376.0000 - mae: 1282.2086 - val_loss: 383939712.0000 - val_mae: 728.1537\n",
      "Epoch 40/50\n",
      "561/561 [==============================] - 0s 711us/step - loss: 304063136.0000 - mae: 678.6117 - val_loss: 63278128.0000 - val_mae: 326.3906\n",
      "Epoch 41/50\n",
      "561/561 [==============================] - 0s 712us/step - loss: 44835840.0000 - mae: 296.0276 - val_loss: 95175048.0000 - val_mae: 304.8446\n",
      "Epoch 42/50\n",
      "561/561 [==============================] - 0s 718us/step - loss: 339145568.0000 - mae: 587.0494 - val_loss: 49700548.0000 - val_mae: 223.2309\n",
      "Epoch 43/50\n",
      "561/561 [==============================] - 0s 710us/step - loss: 108125048.0000 - mae: 354.5110 - val_loss: 12939042.0000 - val_mae: 148.4386\n",
      "Epoch 44/50\n",
      "561/561 [==============================] - 0s 726us/step - loss: 8456876.0000 - mae: 144.5699 - val_loss: 453684.3125 - val_mae: 83.7833\n",
      "Epoch 45/50\n",
      "561/561 [==============================] - 0s 716us/step - loss: 232698.8750 - mae: 78.2503 - val_loss: 34398.9609 - val_mae: 67.5529\n",
      "Epoch 46/50\n",
      "561/561 [==============================] - 0s 719us/step - loss: 18185.2598 - mae: 66.2571 - val_loss: 26761.7012 - val_mae: 65.9919\n",
      "Epoch 47/50\n",
      "561/561 [==============================] - 0s 721us/step - loss: 15687.1016 - mae: 65.2269 - val_loss: 13870.6133 - val_mae: 71.9723\n",
      "Epoch 48/50\n",
      "561/561 [==============================] - 0s 719us/step - loss: 2684395.2500 - mae: 97.4622 - val_loss: 186004.4531 - val_mae: 85.4843\n",
      "Epoch 49/50\n",
      "561/561 [==============================] - 0s 714us/step - loss: 57672.5742 - mae: 75.2533 - val_loss: 174269.5000 - val_mae: 77.3302\n",
      "Epoch 50/50\n",
      "561/561 [==============================] - 0s 713us/step - loss: 53201.6523 - mae: 69.5727 - val_loss: 146494.7500 - val_mae: 71.1408\n",
      "Test RMSE: 35229.32\n",
      "Test R^2: -60089.23\n"
     ]
    }
   ],
   "source": [
    "#Version2 NN: -E\n",
    "# Define model architecture \n",
    "model_NN = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(16, activation='relu'), #added extra layer\n",
    "    keras.layers.Dense(1)  # Output layer for regression\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_NN.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the model \n",
    "history = model_NN.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,  \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate Model\n",
    "y_pred = model_NN.predict(X_test).flatten()\n",
    "\n",
    "# Computing RMSE and R^2\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Test RMSE: {rmse:.2f}\")\n",
    "print(f\"Test R^2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Analysis\n",
    "# Base NN stats: Test RMSE: 74375.01\n",
    "# Test R^2: -287996.45\n",
    "\n",
    "\n",
    "# V2 NN stats: Test RMSE: 15572.84\n",
    "# Test R^2: -12625.13\n",
    "\n",
    "\n",
    "# V2 is significantly better than base NN but still much work needs to be done!\n",
    "\n",
    "# -E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "561/561 [==============================] - 1s 881us/step - loss: 8013740507136.0000 - mae: 68697.9609 - val_loss: 156745875456.0000 - val_mae: 15008.0479\n",
      "Epoch 2/50\n",
      "561/561 [==============================] - 0s 731us/step - loss: 1854794104832.0000 - mae: 30064.3516 - val_loss: 2758417317888.0000 - val_mae: 67544.8672\n",
      "Epoch 3/50\n",
      "561/561 [==============================] - 0s 733us/step - loss: 307150389248.0000 - mae: 11967.0479 - val_loss: 11370401792.0000 - val_mae: 4229.0029\n",
      "Epoch 4/50\n",
      "561/561 [==============================] - 0s 733us/step - loss: 5637531136.0000 - mae: 2464.4724 - val_loss: 2782088960.0000 - val_mae: 2071.9534\n",
      "Epoch 5/50\n",
      "561/561 [==============================] - 0s 735us/step - loss: 1137437952.0000 - mae: 1165.8363 - val_loss: 1126888832.0000 - val_mae: 1539.0773\n",
      "Epoch 6/50\n",
      "561/561 [==============================] - 0s 731us/step - loss: 51676049408.0000 - mae: 6093.6982 - val_loss: 159080873984.0000 - val_mae: 15256.7334\n",
      "Epoch 7/50\n",
      "561/561 [==============================] - 0s 728us/step - loss: 87619715072.0000 - mae: 6601.5146 - val_loss: 260532144.0000 - val_mae: 538.0517\n",
      "Epoch 8/50\n",
      "561/561 [==============================] - 0s 735us/step - loss: 115959680.0000 - mae: 439.4116 - val_loss: 63984188.0000 - val_mae: 381.5011\n",
      "Epoch 9/50\n",
      "561/561 [==============================] - 0s 731us/step - loss: 151292944.0000 - mae: 525.1129 - val_loss: 111260800.0000 - val_mae: 476.6671\n",
      "Epoch 10/50\n",
      "561/561 [==============================] - 0s 736us/step - loss: 380406956032.0000 - mae: 16018.5049 - val_loss: 31469817856.0000 - val_mae: 7456.7334\n",
      "Epoch 11/50\n",
      "561/561 [==============================] - 0s 731us/step - loss: 6787878400.0000 - mae: 2692.0957 - val_loss: 333157760.0000 - val_mae: 613.7695\n",
      "Epoch 12/50\n",
      "561/561 [==============================] - 0s 731us/step - loss: 176858000.0000 - mae: 500.2781 - val_loss: 161314976.0000 - val_mae: 568.7936\n",
      "Epoch 13/50\n",
      "561/561 [==============================] - 0s 734us/step - loss: 118516360.0000 - mae: 468.1451 - val_loss: 160400048.0000 - val_mae: 532.1074\n",
      "Epoch 14/50\n",
      "561/561 [==============================] - 0s 731us/step - loss: 185678848.0000 - mae: 440.9542 - val_loss: 5982159.0000 - val_mae: 175.5404\n",
      "Epoch 15/50\n",
      "561/561 [==============================] - 0s 733us/step - loss: 83889072.0000 - mae: 290.3362 - val_loss: 3219112.7500 - val_mae: 134.2846\n",
      "Epoch 16/50\n",
      "561/561 [==============================] - 0s 732us/step - loss: 29272184.0000 - mae: 207.8099 - val_loss: 1839838.5000 - val_mae: 110.8967\n",
      "Epoch 17/50\n",
      "561/561 [==============================] - 0s 735us/step - loss: 12332899.0000 - mae: 168.2636 - val_loss: 4947590.0000 - val_mae: 155.8451\n",
      "Epoch 18/50\n",
      "561/561 [==============================] - 0s 734us/step - loss: 3233567.2500 - mae: 124.1605 - val_loss: 280481.1562 - val_mae: 86.7069\n",
      "Epoch 19/50\n",
      "561/561 [==============================] - 0s 731us/step - loss: 1946722.8750 - mae: 104.6633 - val_loss: 248554.4688 - val_mae: 84.9973\n",
      "Epoch 20/50\n",
      "561/561 [==============================] - 0s 730us/step - loss: 4669139.5000 - mae: 137.0767 - val_loss: 920937.1250 - val_mae: 106.8696\n",
      "Epoch 21/50\n",
      "561/561 [==============================] - 0s 738us/step - loss: 9710415.0000 - mae: 171.6712 - val_loss: 25654292.0000 - val_mae: 257.4760\n",
      "Epoch 22/50\n",
      "561/561 [==============================] - 0s 734us/step - loss: 175255856.0000 - mae: 442.0956 - val_loss: 26079538.0000 - val_mae: 268.1533\n",
      "Epoch 23/50\n",
      "561/561 [==============================] - 0s 733us/step - loss: 208973312.0000 - mae: 407.8631 - val_loss: 159431456.0000 - val_mae: 560.3015\n",
      "Epoch 24/50\n",
      "561/561 [==============================] - 0s 737us/step - loss: 208545776.0000 - mae: 504.5741 - val_loss: 1197410.7500 - val_mae: 108.2169\n",
      "Epoch 25/50\n",
      "561/561 [==============================] - 0s 734us/step - loss: 21717106.0000 - mae: 175.0291 - val_loss: 70327.6562 - val_mae: 72.3067\n",
      "Epoch 26/50\n",
      "561/561 [==============================] - 0s 733us/step - loss: 319829.2188 - mae: 78.8959 - val_loss: 231067.2656 - val_mae: 84.3517\n",
      "Epoch 27/50\n",
      "561/561 [==============================] - 0s 738us/step - loss: 1146818.1250 - mae: 83.5625 - val_loss: 120831872.0000 - val_mae: 478.5797\n",
      "Epoch 28/50\n",
      "561/561 [==============================] - 0s 736us/step - loss: 1288520448.0000 - mae: 657.6362 - val_loss: 1256922.3750 - val_mae: 85.5720\n",
      "Epoch 29/50\n",
      "561/561 [==============================] - 0s 739us/step - loss: 178974720.0000 - mae: 422.3686 - val_loss: 11909.8604 - val_mae: 59.8416\n",
      "Epoch 30/50\n",
      "561/561 [==============================] - 0s 737us/step - loss: 11857.6084 - mae: 62.4294 - val_loss: 12391.2939 - val_mae: 61.0080\n",
      "Epoch 31/50\n",
      "561/561 [==============================] - 0s 735us/step - loss: 34182.5000 - mae: 65.3995 - val_loss: 78212.5781 - val_mae: 70.6661\n",
      "Epoch 32/50\n",
      "561/561 [==============================] - 0s 737us/step - loss: 26189358.0000 - mae: 198.2536 - val_loss: 738759.8750 - val_mae: 96.3195\n",
      "Epoch 33/50\n",
      "561/561 [==============================] - 0s 740us/step - loss: 638794.8750 - mae: 71.2365 - val_loss: 11630.8271 - val_mae: 62.7262\n",
      "Epoch 34/50\n",
      "561/561 [==============================] - 0s 741us/step - loss: 12204.8096 - mae: 62.4257 - val_loss: 11247.3457 - val_mae: 60.1003\n",
      "Epoch 35/50\n",
      "561/561 [==============================] - 0s 732us/step - loss: 12952.6250 - mae: 61.9843 - val_loss: 11202.7334 - val_mae: 59.2954\n",
      "Epoch 36/50\n",
      "561/561 [==============================] - 0s 737us/step - loss: 11900.0752 - mae: 61.7794 - val_loss: 11288.5811 - val_mae: 63.5433\n",
      "Epoch 37/50\n",
      "561/561 [==============================] - 0s 739us/step - loss: 11413.6855 - mae: 61.3735 - val_loss: 11183.0205 - val_mae: 58.7259\n",
      "Epoch 38/50\n",
      "561/561 [==============================] - 0s 736us/step - loss: 10410708.0000 - mae: 85.8870 - val_loss: 28430.2891 - val_mae: 64.0973\n",
      "Epoch 39/50\n",
      "561/561 [==============================] - 0s 729us/step - loss: 15735.2900 - mae: 63.1866 - val_loss: 14460.2559 - val_mae: 62.9364\n",
      "Epoch 40/50\n",
      "561/561 [==============================] - 0s 737us/step - loss: 51284238336.0000 - mae: 2948.1790 - val_loss: 31049346.0000 - val_mae: 190.3349\n",
      "Epoch 41/50\n",
      "561/561 [==============================] - 0s 747us/step - loss: 6078862.0000 - mae: 100.7714 - val_loss: 12840.0098 - val_mae: 63.9473\n",
      "Epoch 42/50\n",
      "561/561 [==============================] - 0s 750us/step - loss: 12229.0088 - mae: 63.6094 - val_loss: 12140.8799 - val_mae: 62.0232\n",
      "Epoch 43/50\n",
      "561/561 [==============================] - 0s 741us/step - loss: 11765.5234 - mae: 62.4132 - val_loss: 11754.7959 - val_mae: 60.0911\n",
      "Epoch 44/50\n",
      "561/561 [==============================] - 0s 733us/step - loss: 11563.2227 - mae: 62.0504 - val_loss: 11825.9131 - val_mae: 59.1899\n",
      "Epoch 45/50\n",
      "561/561 [==============================] - 0s 736us/step - loss: 11410.8447 - mae: 61.5394 - val_loss: 11558.3662 - val_mae: 61.2167\n",
      "Epoch 46/50\n",
      "561/561 [==============================] - 0s 734us/step - loss: 11329.6035 - mae: 61.5998 - val_loss: 11586.6035 - val_mae: 59.6367\n",
      "Epoch 47/50\n",
      "561/561 [==============================] - 0s 733us/step - loss: 11258.8096 - mae: 61.1795 - val_loss: 11419.6523 - val_mae: 58.4796\n",
      "Epoch 48/50\n",
      "561/561 [==============================] - 0s 736us/step - loss: 11133.4619 - mae: 60.9020 - val_loss: 11356.3877 - val_mae: 58.3278\n",
      "Epoch 49/50\n",
      "561/561 [==============================] - 0s 739us/step - loss: 11113.5693 - mae: 60.8206 - val_loss: 11288.6855 - val_mae: 59.4314\n",
      "Epoch 50/50\n",
      "561/561 [==============================] - 0s 734us/step - loss: 11048.7178 - mae: 60.7350 - val_loss: 11383.5850 - val_mae: 61.0618\n",
      "Test RMSE: 105.73\n",
      "Test R^2: 0.46\n"
     ]
    }
   ],
   "source": [
    "#Version3 NN: -T\n",
    "# Define model architecture \n",
    "model_NN = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(16, activation='relu'), #added extra layer\n",
    "    keras.layers.Dense(8, activation='relu'), #added extra layer\n",
    "    keras.layers.Dense(1)  # Output layer for regression\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_NN.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the model \n",
    "history = model_NN.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,              \n",
    "    batch_size=32,\n",
    "    validation_split=0.2,   \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate Model\n",
    "y_pred = model_NN.predict(X_test).flatten()\n",
    "\n",
    "# Computing RMSE and R^2\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Test RMSE: {rmse:.2f}\")\n",
    "print(f\"Test R^2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Analysis\n",
    "# V2 NN stats: Test RMSE: 15572.84\n",
    "# Test R^2: -12625.13\n",
    "\n",
    "# V3 NN stats: Test RMSE: 103.93\n",
    "# Test R^2: 0.44\n",
    "\n",
    "# Linear Regression Model:\n",
    "# RMSE: 110.73\n",
    "# R^2: 0.39\n",
    "\n",
    "# V3 is significantly better than V2 NN but still \n",
    "# some work needs to be done but it is very close to the LR model :)\n",
    "\n",
    "\n",
    "# -T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "561/561 [==============================] - 1s 911us/step - loss: 43271.5820 - mae: 153.8392 - val_loss: 43096.6992 - val_mae: 152.9964\n",
      "Epoch 2/50\n",
      "561/561 [==============================] - 0s 760us/step - loss: 43101.4844 - mae: 153.2847 - val_loss: 42927.9492 - val_mae: 152.4438\n",
      "Epoch 3/50\n",
      "561/561 [==============================] - 0s 761us/step - loss: 42932.3711 - mae: 152.7336 - val_loss: 42759.7539 - val_mae: 151.8915\n",
      "Epoch 4/50\n",
      "561/561 [==============================] - 0s 756us/step - loss: 42764.3828 - mae: 152.1792 - val_loss: 42592.9375 - val_mae: 151.3414\n",
      "Epoch 5/50\n",
      "561/561 [==============================] - 0s 761us/step - loss: 42597.1836 - mae: 151.6293 - val_loss: 42426.5156 - val_mae: 150.7906\n",
      "Epoch 6/50\n",
      "561/561 [==============================] - 0s 762us/step - loss: 42430.3164 - mae: 151.0805 - val_loss: 42260.5234 - val_mae: 150.2388\n",
      "Epoch 7/50\n",
      "561/561 [==============================] - 0s 760us/step - loss: 42264.2109 - mae: 150.5291 - val_loss: 42095.6992 - val_mae: 149.6896\n",
      "Epoch 8/50\n",
      "561/561 [==============================] - 0s 758us/step - loss: 42098.9609 - mae: 149.9777 - val_loss: 41931.3594 - val_mae: 149.1396\n",
      "Epoch 9/50\n",
      "561/561 [==============================] - 0s 757us/step - loss: 41934.1641 - mae: 149.4308 - val_loss: 41767.3984 - val_mae: 148.5888\n",
      "Epoch 10/50\n",
      "561/561 [==============================] - 0s 759us/step - loss: 41770.0664 - mae: 148.8778 - val_loss: 41604.4844 - val_mae: 148.0394\n",
      "Epoch 11/50\n",
      "561/561 [==============================] - 0s 757us/step - loss: 41606.5898 - mae: 148.3293 - val_loss: 41441.7109 - val_mae: 147.4886\n",
      "Epoch 12/50\n",
      "561/561 [==============================] - 0s 759us/step - loss: 41443.7656 - mae: 147.7793 - val_loss: 41279.7773 - val_mae: 146.9390\n",
      "Epoch 13/50\n",
      "561/561 [==============================] - 0s 762us/step - loss: 41281.5898 - mae: 147.2285 - val_loss: 41118.6602 - val_mae: 146.3896\n",
      "Epoch 14/50\n",
      "561/561 [==============================] - 0s 763us/step - loss: 41120.1133 - mae: 146.6792 - val_loss: 40958.1523 - val_mae: 145.8402\n",
      "Epoch 15/50\n",
      "561/561 [==============================] - 0s 764us/step - loss: 40959.2578 - mae: 146.1290 - val_loss: 40798.1328 - val_mae: 145.2907\n",
      "Epoch 16/50\n",
      "464/561 [=======================>......] - ETA: 0s - loss: 40578.8086 - mae: 145.1550"
     ]
    }
   ],
   "source": [
    "#Version4 NN: -E\n",
    "# Define model architecture \n",
    "model_NN = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(16, activation='relu'), #added extra layer\n",
    "    keras.layers.Dense(8, activation='relu'), #added extra layer\n",
    "    keras.layers.Dense(4, activation='relu'), #added extra layer \n",
    "    keras.layers.Dense(1)  # Output layer for regression\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_NN.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the model \n",
    "history = model_NN.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,             \n",
    "    batch_size=32,\n",
    "    validation_split=0.2,  \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate Model\n",
    "y_pred = model_NN.predict(X_test).flatten()\n",
    "\n",
    "# Computing RMSE and R^2\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Test RMSE: {rmse:.2f}\")\n",
    "print(f\"Test R^2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Analysis\n",
    "\n",
    "# V3 NN stats: Test RMSE: 103.93\n",
    "# Test R^2: 0.44\n",
    "\n",
    "# V4 NN stats: Test RMSE: 108.35\n",
    "# Test R^2: 0.39\n",
    "\n",
    "# Linear Regression Model:\n",
    "# RMSE: 110.73\n",
    "# R^2: 0.39\n",
    "\n",
    "# V4 is better than V3 NN but is now out performing the LR model. R^2 is the same but the RMSE is now better!!\n",
    "# Tried a smaller epoch but performed much worse so we are keeping epoch at 50.\n",
    "# Going to try another layer!\n",
    "\n",
    "\n",
    "# -E\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Version5 NN: -T\n",
    "# Define model architecture \n",
    "model_NN = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(16, activation='relu'), #added extra layer\n",
    "    keras.layers.Dense(16, activation='relu'), #added extra layer\n",
    "    keras.layers.Dense(8, activation='relu'), #added extra layer\n",
    "    keras.layers.Dense(4, activation='relu'), #added extra layer \n",
    "    keras.layers.Dense(1)  # Output layer for regression\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_NN.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the model \n",
    "history = model_NN.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,             \n",
    "    batch_size=32,\n",
    "    validation_split=0.2,  \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate Model\n",
    "y_pred = model_NN.predict(X_test).flatten()\n",
    "\n",
    "# Computing RMSE and R^2\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Test RMSE: {rmse:.2f}\")\n",
    "print(f\"Test R^2: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Analysis\n",
    "# V4 NN stats: Test RMSE: 108.35\n",
    "# Test R^2: 0.39\n",
    "\n",
    "# V5 NN stats: Test RMSE: 122.74\n",
    "# Test R^2: 0.22\n",
    "\n",
    "# Linear Regression Model:\n",
    "# RMSE: 110.73\n",
    "# R^2: 0.39\n",
    "\n",
    "\n",
    "# V4 and V5 differ, V4 has a better rmse value but V5 has a better R^2 value. It depends on the use on which model would be better since RMSE is more meaningful for practical errors, and R^2 tells you how well your model explains the data pattern.\n",
    "\n",
    "\n",
    "# -T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Final Analysis\n",
    "\n",
    "# We think V4 or V5 are the best models and it really depends on your use \n",
    "# for which would be best to use! In the context of our goal \n",
    "# for the model we believe its best to have a better RMSE value \n",
    "# so V4 would be better in terms of trying to see the predicted\n",
    "# price point for an airbnb.\n",
    "\n",
    "# -T and E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
